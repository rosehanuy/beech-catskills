{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray \n",
    "from shapely.geometry import box\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from geocube.api.core import make_geocube\n",
    "\n",
    "\n",
    "\n",
    "root = Path.cwd()\n",
    "\n",
    "\n",
    "class Site():\n",
    "    def __init__(self,site_name,sentinel_data,polygons):\n",
    "        self.site_name = site_name\n",
    "        self.sentinel_data = sentinel_data.rio.write_crs(26918).rio.set_spatial_dims(x_dim=\"x\",y_dim=\"y\",).rio.write_coordinate_system()\n",
    "        self.polygons = polygons.reset_index().to_crs(26918)\n",
    "        self.bbox = self.get_bbox()\n",
    "\n",
    "        self.site_polygons = self.get_site_polygons()\n",
    "\n",
    "        self.beech_idx = self.site_polygons.loc[self.site_polygons.Name!='non-beech stand']['index'].astype('float').values\n",
    "        self.nonbeech_idx = self.site_polygons.loc[self.site_polygons.Name=='non-beech stand']['index'].astype('float').values\n",
    "\n",
    "        self.raster_polys = self.rasterize_polys()\n",
    "\n",
    "    def get_bbox(self):\n",
    "        b = self.sentinel_data.rio.bounds()\n",
    "        return box(*b)\n",
    "    \n",
    "    def get_site_polygons(self):\n",
    "        df = gpd.GeoDataFrame({\"id\":1,\"geometry\":[self.bbox]})\n",
    "        idx = df.sindex.query(self.polygons.geometry, predicate=\"intersects\")[0]\n",
    "        return self.polygons.iloc[idx]\n",
    "    \n",
    "    # rasterize polygons\n",
    "    def rasterize_polys(self):\n",
    "        g = make_geocube(\n",
    "        vector_data=self.site_polygons,\n",
    "        measurements=[\"index\"],\n",
    "        like=self.sentinel_data, # ensure the data are on the same grid\n",
    "    )\n",
    "        return g\n",
    "    \n",
    "    # plot rasterized polygons overlaid with vector polygons\n",
    "    def plot_rasterized_polys(self):\n",
    "        fig, ax = plt.subplots(ncols=1, figsize=(5, 5))\n",
    "\n",
    "        p = self.raster_polys.index.plot.imshow(ax=ax)\n",
    "        self.site_polygons.plot(ax=ax,alpha=.7)\n",
    "        p.colorbar.remove()\n",
    "        plt.title(f'Rasterized Polygons: {self.site_name.title()} Site')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # store pixel values for each plot in dataframe\n",
    "    def make_pixel_df(self,idx='beech'):\n",
    "        \n",
    "        if idx == 'beech':\n",
    "            id = self.beech_idx\n",
    "        else:\n",
    "            id = self.nonbeech_idx\n",
    "\n",
    "        if len(id) == 1:\n",
    "            pixels = self.sentinel_data.where(self.raster_polys.index==id).assign_coords({'time':[str(x.astype('datetime64[D]')) for x in self.sentinel_data.time.values]})\n",
    "        else:\n",
    "            pixels = self.sentinel_data.where((self.raster_polys.index==id[0])|(self.raster_polys.index==id[1]))\n",
    "\n",
    "        stacked = pixels.stack(spatial=('x','y'))\n",
    "        transposed = stacked.transpose('spatial', 'band', 'time')\n",
    "        # convert to dataframe\n",
    "        df = transposed.to_dataframe(name='value').unstack(['band', 'time'])\n",
    "\n",
    "        df = df.loc[:,('value')]\n",
    "\n",
    "        df.columns = df.columns.set_levels([str(x.astype('datetime64[D]')) for x in self.sentinel_data.time.values],level='time')\n",
    "        df = df.reset_index()\n",
    "\n",
    "        df.columns = [f'{x[0]}_{x[1]}' for x in df.columns]\n",
    "\n",
    "        df.rename(columns={df.columns[0]:'x',df.columns[1]:'y'},inplace=True)\n",
    "\n",
    "        df = df.drop(['x','y'],axis=1)\n",
    "\n",
    "        df = df[df.isna().sum(axis=1) == 0]\n",
    "        print(df.shape)\n",
    "\n",
    "        return df\n",
    "        \n",
    "\n",
    "    \n",
    "    # store mean values for each plot in dataframe\n",
    "    def make_site_means_df(self, i='beech'):\n",
    "\n",
    "        out_grid = self.raster_polys\n",
    "    \n",
    "        out_grid['sentinel'] = (self.sentinel_data.dims, self.sentinel_data.values, self.sentinel_data.attrs, self.sentinel_data.encoding)\n",
    "\n",
    "        # calculate means for each group (polygon)\n",
    "        grouped_sentinel = out_grid.drop_vars(\"spatial_ref\").groupby(out_grid.index)\n",
    "        grid_mean = grouped_sentinel.mean().rename({\"sentinel\": \"sentinel_mean\"})\n",
    "\n",
    "        zonal_stats = grid_mean.to_dataframe()\n",
    "\n",
    "        # put beech/nonbeech into seperate dataframes \n",
    "        if i == 'beech':\n",
    "            idx = self.beech_idx\n",
    "        else:\n",
    "            idx = self.nonbeech_idx\n",
    "        \n",
    "        df = zonal_stats.loc[idx]\n",
    "        \n",
    "        df_unstack = df.unstack(level='band').droplevel('band',axis=1)\n",
    "        df_unstack.columns = self.sentinel_data.band.values\n",
    "\n",
    "        if len(np.unique(df_unstack.index.get_level_values(level='index'))) < 2: # check if multiple polygons\n",
    "            df_unstack = df_unstack.reset_index()\n",
    "            df_unstack['time'] = [str(x.astype('datetime64[D]')) for x in self.sentinel_data.time.values]\n",
    "            return df_unstack\n",
    "        \n",
    "        else:   # if multiple polygons, return a list of dataframes\n",
    "            df_list = []\n",
    "            for i in range(0,len(idx)):\n",
    "                df1 = df_unstack.loc[idx[i]]\n",
    "                df1 = df1.reset_index()\n",
    "                df1['time'] = [str(x.astype('datetime64[D]')) for x in self.sentinel_data.time.values]\n",
    "                df_list.append(df1)\n",
    "            \n",
    "            return df_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "polys = gpd.read_file(root / 'beech_stands' / 'Beech Stand Polygons.kml')\n",
    "\n",
    "SITE = 'pecoy'\n",
    "pecoy_sentinel = xr.open_dataarray(root / 'sentinel_data' / f'2023_{SITE}.nc')\n",
    "\n",
    "SITE = 'roundtop'\n",
    "roundtop_sentinel = xr.open_dataarray(root / 'sentinel_data' / f'2023_{SITE}.nc')\n",
    "\n",
    "SITE = 'visitors'\n",
    "visitors_sentinel = xr.open_dataarray(root / 'sentinel_data' / f'2023_{SITE}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pecoy = Site('Pecoy',pecoy_sentinel, polys)\n",
    "roundtop = Site('Roundtop',roundtop_sentinel,polys)\n",
    "visitors = Site('Visitors',visitors_sentinel,polys)\n",
    "\n",
    "beech_pixels = pd.concat([pecoy.make_pixel_df('beech'),roundtop.make_pixel_df('beech'),visitors.make_pixel_df('beech')])\n",
    "nonbeech_pixels = pd.concat([pecoy.make_pixel_df('nonbeech'),roundtop.make_pixel_df('nonbeech'),visitors.make_pixel_df('nonbeech')])\n",
    "\n",
    "beech_pixels.to_csv(root / 'output' / 'beech_sentinel_pixels.csv')\n",
    "nonbeech_pixels.to_csv(root / 'output' / 'nonbeech_sentinel_pixels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get mean values for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roseh\\miniconda3\\envs\\beech-env\\Lib\\site-packages\\xarray\\core\\concat.py:540: UserWarning: No index created for dimension index because variable index is not a coordinate. To create an index for index, please first call `.set_coords('index')` on this object.\n",
      "  ds.expand_dims(dim_name, create_index_for_new_dim=create_index_for_new_dim)\n"
     ]
    }
   ],
   "source": [
    "# add satellite data to dataset\n",
    "out_grid['sentinel'] = (sentinel.dims, sentinel.values, sentinel.attrs, sentinel.encoding)\n",
    "\n",
    "# calculate means for each group (polygon)\n",
    "grouped_sentinel = out_grid.drop_vars(\"spatial_ref\").groupby(out_grid.index)\n",
    "grid_mean = grouped_sentinel.mean().rename({\"sentinel\": \"sentinel_mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonal_stats = grid_mean.to_dataframe()\n",
    "\n",
    "# put beech/nonbeech into seperate dataframes \n",
    "beech_means = zonal_stats.loc[beech_idx]\n",
    "nonbeech_means = zonal_stats.loc[nonbeech_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_site_means_dfs(self, i='beech'):\n",
    "\n",
    "    out_grid = self.raster_polys\n",
    "   \n",
    "    out_grid['sentinel'] = (self.sentinel_data.dims, self.sentinel_data.values, self.sentinel_data.attrs, self.sentinel_data.encoding)\n",
    "\n",
    "    # calculate means for each group (polygon)\n",
    "    grouped_sentinel = out_grid.drop_vars(\"spatial_ref\").groupby(out_grid.index)\n",
    "    grid_mean = grouped_sentinel.mean().rename({\"sentinel\": \"sentinel_mean\"})\n",
    "\n",
    "    zonal_stats = grid_mean.to_dataframe()\n",
    "\n",
    "    # put beech/nonbeech into seperate dataframes \n",
    "    if i == 'beech':\n",
    "        df = zonal_stats.loc[self.beech_idx]\n",
    "    else:\n",
    "        df = zonal_stats.loc[self.nonbeech_idx]\n",
    "    \n",
    "    df_unstack = df.unstack(level='band').droplevel('band',axis=1)\n",
    "    df_unstack.columns = self.sentinel_data.band.values\n",
    "\n",
    "    if len(np.unique(df_unstack.index.get_level_values(level='index'))) < 2: # check if multiple polygons\n",
    "        df_unstack = df_unstack.reset_index()\n",
    "        df_unstack['time'] = [str(x.astype('datetime64[D]')) for x in self.sentinel_data.time.values]\n",
    "        return df_unstack\n",
    "    \n",
    "    else:   # if multiple polygons, return a list of dataframes\n",
    "        df_list = []\n",
    "        for i in range(0,len(idx)):\n",
    "            df1 = df_unstack.loc[idx[i]]\n",
    "            df1 = df1.reset_index()\n",
    "            df1['time'] = [str(x.astype('datetime64[D]')) for x in self.sentinel_data.time.values]\n",
    "            df_list.append(df1)\n",
    "        \n",
    "        return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unstack_and_relabel_dfs(df,idx=None):\n",
    "    \"\"\"Reformat and tidy dataframes produced by calling to_dataframe() on zonal stats array\"\"\"\n",
    "\n",
    "    df_unstack = df.unstack(level='band').droplevel('band',axis=1)\n",
    "    df_unstack.columns = sentinel.band.values\n",
    "\n",
    "    if len(np.unique(df_unstack.index.get_level_values(level='index'))) < 2: # check if multiple polygons\n",
    "        df_unstack = df_unstack.reset_index()\n",
    "        df_unstack['time'] = [str(x.astype('datetime64[D]')) for x in sentinel.time.values]\n",
    "        return df_unstack\n",
    "    \n",
    "    else:   # if multiple polygons, return a list of dataframes\n",
    "        df_list = []\n",
    "        for i in range(0,len(idx)):\n",
    "            df1 = df_unstack.loc[idx[i]]\n",
    "            df1 = df1.reset_index()\n",
    "            df1['time'] = [str(x.astype('datetime64[D]')) for x in sentinel.time.values]\n",
    "            df_list.append(df1)\n",
    "        \n",
    "        return df_list\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat and label dataframes\n",
    "beech_means = unstack_and_relabel_dfs(beech_means)\n",
    "nonbeech_means = unstack_and_relabel_dfs(nonbeech_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk\n",
    "beech_means.to_csv(root / 'output' / f'{SITE}_beech_polygon_means.csv')\n",
    "nonbeech_means.to_csv(root / 'output' / f'{SITE}_nonbeech_polygon_means.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beech-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
